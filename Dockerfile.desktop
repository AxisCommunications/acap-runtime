# Dockerfile for larod-inference-server on desktop
FROM larod-server as build

# Install Edge<TPU compiler
RUN echo "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main" | tee /etc/apt/sources.list.d/coral-edgetpu.list &&\
    curl -k https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - &&\
    apt-get update && apt-get install -y --no-install-recommends \
    edgetpu-compiler

# Download and install Larodconverter
RUN apt-get update && apt-get install -y --no-install-recommends python3-pip
ADD https://artifacts.se.axis.com/artifactory/ft-ecp/Larodconverter/Larodconverter-1.0-py3-none-any.whl /opt/axis/tools/
RUN pip3 install /opt/axis/tools/Larodconverter*.whl

# Get testdata models
WORKDIR /opt/larod-inference-server/testdata

# Get SSD Mobilenet V2
ADD https://github.com/google-coral/edgetpu/raw/master/test_data/ssd_mobilenet_v2_coco_quant_postprocess_edgetpu.tflite tmp/
ADD https://github.com/google-coral/edgetpu/raw/master/test_data/ssd_mobilenet_v2_coco_quant_postprocess.tflite tmp/
ADD https://github.com/google-coral/edgetpu/raw/master/test_data/coco_labels.txt .
ADD https://github.com/google-coral/edgetpu/raw/master/test_data/grace_hopper.bmp .
RUN cd tmp &&\
    larod-convert.py tflite ssd_mobilenet_v2_coco_quant_postprocess_edgetpu.tflite &&\
    larod-convert.py tflite ssd_mobilenet_v2_coco_quant_postprocess.tflite &&\
    mv *.larod .. &&\
    cd .. && rm -rf tmp

# Get Mobilenet V2
ADD http://download.tensorflow.org/models/tflite_11_05_08/mobilenet_v2_1.0_224_quant.tgz tmp/
ADD https://github.com/google-coral/edgetpu/raw/master/test_data/mobilenet_v2_1.0_224_quant_edgetpu.tflite tmp/
ADD https://github.com/google-coral/edgetpu/raw/master/test_data/imagenet_labels.txt .
RUN cd tmp &&\
    tar -xvf mobilenet_v2_1.0_224_quant.tgz &&\
	larod-convert.py tflite mobilenet_v2_1.0_224_quant_edgetpu.tflite &&\
	larod-convert.py tflite mobilenet_v2_1.0_224_quant.tflite &&\
    mv *.larod .. &&\
    cd .. && rm -rf tmp

# Get EfficientNet-EdgeTpu (M)
ADD https://github.com/google-coral/test_data/raw/master/efficientnet-edgetpu-M_quant_edgetpu.tflite tmp/efficientnet-edgetpu-M_quant_edgetpu.tflite
ADD https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/efficientnet-edgetpu-M.tar.gz tmp/
RUN cd tmp &&\
    tar -xvf efficientnet-edgetpu-M.tar.gz &&\
    cd efficientnet-edgetpu-M &&\
	larod-convert.py tflite efficientnet-edgetpu-M_quant.tflite &&\
    edgetpu_compiler efficientnet-edgetpu-M_quant.tflite &&\
	larod-convert.py tflite efficientnet-edgetpu-M_quant_edgetpu.tflite &&\
    mv *.larod ../.. &&\
    cd ../.. && rm -rf tmp

# Get Tensorflow
WORKDIR /opt/larod-inference-server
ARG TENSORFLOW_DIR=/opt/tensorflow/tensorflow
RUN git clone -b r1.14 https://github.com/tensorflow/tensorflow.git $TENSORFLOW_DIR

# Get Tensorflow Serving
RUN git clone -b r1.14 https://github.com/tensorflow/serving.git /opt/tensorflow/serving
RUN mkdir apis &&\
    cd apis &&\
    ln -fs /opt/tensorflow/tensorflow/tensorflow &&\
    ln -fs /opt/tensorflow/serving/tensorflow_serving

## Copy source files
COPY . ./

##  Build and install
RUN make install
RUN ldconfig

FROM debian:buster-slim
COPY --from=build /usr/lib /usr/lib
COPY --from=build /usr/local/lib/x86_64-linux-gnu /usr/lib
COPY --from=build /usr/bin /usr/bin
COPY --from=build /usr/local/bin /usr/bin
COPY --from=build /opt/larod-inference-server/testdata /testdata

# This container is used for finding out what libraries larod-inference-server
# needs, and the outcome is the list above of libraries to preserve.
#ENTRYPOINT [ "/usr/bin/ldd",  "/usr/bin/larod-inference-server" ]
#CMD ["/usr/bin/larod-inference-server"]